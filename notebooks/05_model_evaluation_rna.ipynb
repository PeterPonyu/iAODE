{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Evaluation (scRNA-seq)\n\nConverted from `examples/model_evaluation_rna.py`\n\n**Note:** This notebook contains the full example code. Run cells sequentially."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "\"\"\"\nModel evaluation and benchmarking (scRNA-seq \u2013 paul15)\n\nComprehensive comparison of iAODE vs. scVI-family models using\nLatent Space Evaluation (LSE) metrics on a trajectory dataset.\n\nDataset: paul15 (hematopoietic scRNA-seq trajectory)\n\"\"\"\n\nimport sys\nfrom pathlib import Path\n\nsys.path.insert(0, str(Path(__file__).parent))\nfrom _example_utils import (\n    check_iaode_installed, setup_output_dir,\n    print_header, print_section, print_success,\n    print_info, print_warning\n)\n\nif not check_iaode_installed():\n    sys.exit(1)\n\nimport iaode\nimport scanpy as sc  # type: ignore\nimport numpy as np\nimport pandas as pd  # type: ignore\nimport matplotlib.pyplot as plt\nfrom matplotlib import gridspec\nimport warnings\nwarnings.filterwarnings('ignore')"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ==================================================\n# Configuration"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ==================================================\n\nCONFIG = {\n    'epochs': 100,\n    'patience': 20,\n    'val_every': 5,\n    'latent_dim': 10,\n    'hidden_dim': 128,\n    'batch_size': 128,\n    'test_size': 0.15,\n    'val_size': 0.15,\n    'random_seed': 42,\n}\n\nOUTPUT_DIR = setup_output_dir(\"model_evaluation\")\nprint_info(f\"Saving outputs to: {OUTPUT_DIR}\")\nprint_info(f\"Configuration: {CONFIG['epochs']} epochs, latent_dim={CONFIG['latent_dim']}\")\nprint()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ==================================================\n# Load Data"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ==================================================\n\nprint_header(\"Model evaluation & benchmarking (paul15)\")\n\nprint_section(\"Loading paul15 dataset\")\nadata = sc.datasets.paul15()\n\n# Basic QC\nsc.pp.filter_cells(adata, min_genes=200)\n\n# Store raw counts BEFORE normalization\nfrom scipy.sparse import issparse  # type: ignore\nif issparse(adata.X):\n    adata.layers['counts'] = adata.X.copy()\nelse:\n    adata.layers['counts'] = np.asarray(adata.X.copy())\n\n# Normalize for downstream analysis (not used by iAODE loss)\nsc.pp.normalize_total(adata, target_sum=1e4)\nsc.pp.log1p(adata)\n\nprint_success(f\"Loaded: {adata.n_obs} cells \u00d7 {adata.n_vars} genes\")\nprint()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ==================================================\n# Train/Val/Test Split"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ==================================================\n\nprint_section(\"Creating train/validation/test splits\")\n\nsplitter = iaode.DataSplitter(\n    n_samples=adata.n_obs,\n    test_size=CONFIG['test_size'],\n    val_size=CONFIG['val_size'],\n    random_state=CONFIG['random_seed']\n)\n\nprint_info(\n    f\"Train: {len(splitter.train_idx)} | \"\n    f\"Val: {len(splitter.val_idx)} | \"\n    f\"Test: {len(splitter.test_idx)} cells\"\n)\nprint()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ==================================================\n# Train iAODE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ==================================================\n\nprint_section(\"Training iAODE (Neural ODE)\")\n\nmodel = iaode.agent(\n    adata,\n    layer='counts',\n    latent_dim=int(CONFIG['latent_dim']),\n    hidden_dim=int(CONFIG['hidden_dim']),\n    use_ode=True,\n    encoder_type='mlp',\n    loss_mode='nb',          # Negative binomial for counts\n    batch_size=int(CONFIG['batch_size'])\n)\n\nmodel.fit(\n    epochs=int(CONFIG['epochs']),\n    patience=int(CONFIG['patience']),\n    val_every=int(CONFIG['val_every'])\n)\n\nlatent_iaode = model.get_latent()\nmetrics_iaode = model.get_resource_metrics()\n\nprint_success(\n    f\"iAODE trained in {metrics_iaode['train_time']:.2f}s \"\n    f\"({metrics_iaode['actual_epochs']} epochs)\"\n)\nprint()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ==================================================\n# Evaluate iAODE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ==================================================\n\nprint_section(\"Evaluating iAODE on test set (LSE metrics)\")\n\nlatent_iaode_test = latent_iaode[splitter.test_idx]\nX_high_test = adata[splitter.test_idx].layers['counts']\nif hasattr(X_high_test, 'toarray'):\n    X_high_test = X_high_test.toarray()\n\nls_metrics = iaode.evaluate_single_cell_latent_space(\n    latent_space=latent_iaode_test,\n    data_type='trajectory',\n    verbose=True\n)\n\nresults = {\n    'iAODE': {\n        'latent': latent_iaode_test,\n        'adata_subset': adata[splitter.test_idx].copy(),\n        'train_time': metrics_iaode['train_time'],\n        'epochs': metrics_iaode['actual_epochs'],\n        'ls_metrics': ls_metrics,\n    }\n}\n\nprint()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ==================================================\n# Train and Evaluate scVI-family Models"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ==================================================\n\nprint_section(\"Training scVI-family models\")\n\nscvi_results = iaode.train_scvi_models(\n    adata, splitter,\n    n_latent=CONFIG['latent_dim'],\n    n_epochs=CONFIG['epochs'],\n    batch_size=CONFIG['batch_size']\n)\n\nprint_section(\"Evaluating scVI-family models (LSE metrics)\")\n\nfor model_name, result in scvi_results.items():\n    if result is None:\n        continue\n\n    print_info(f\"Evaluating {model_name.upper()}\")\n\n    latent_scvi = result['model'].get_latent_representation(result['adata_test'])\n\n    try:\n        ls_scvi = iaode.evaluate_single_cell_latent_space(\n            latent_space=latent_scvi,\n            data_type='trajectory',\n            verbose=False\n        )\n    except Exception as e:\n        print_warning(f\"LSE metrics failed for {model_name}: {e}\")\n        ls_scvi = {}\n\n    results[model_name] = {\n        'latent': latent_scvi,\n        'adata_subset': result['adata_test'].copy(),\n        'train_time': result['train_time'],\n        'epochs': result.get('epochs', CONFIG['epochs']),\n        'ls_metrics': ls_scvi,\n    }\n\n    print_success(f\"{model_name.upper()} evaluated\")\nprint()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ==================================================\n# Build Comparison Table"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ==================================================\n\nprint_section(\"Building comparison table\")\n\ncomparison_data = []\nfor model_name, data in results.items():\n    row = {\n        'Model': model_name,\n        'Train Time (s)': data['train_time'],\n        'Epochs': data['epochs'],\n    }\n\n    ls = data.get('ls_metrics', {})\n    row['Manifold Dim'] = ls.get('manifold_dimensionality', np.nan)\n    row['Spectral Decay'] = ls.get('spectral_decay_rate', np.nan)\n    row['Trajectory Dir'] = ls.get('trajectory_directionality', np.nan)\n\n    comparison_data.append(row)\n\ndf = pd.DataFrame(comparison_data)\nprint()\nprint(df.to_string(index=False))\nprint()\n\ncsv_path = OUTPUT_DIR / 'model_comparison.csv'\ndf.to_csv(csv_path, index=False)\nprint_success(f\"Saved table: {csv_path}\")\nprint()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ==================================================\n# UMAP for Visualization"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ==================================================\n\nprint_section(\"Computing UMAP embeddings from latent spaces\")\n\nfor model_name, data in results.items():\n    adata_viz = data['adata_subset'].copy()\n    adata_viz.obsm['X_latent'] = data['latent']\n    sc.pp.neighbors(adata_viz, use_rep='X_latent', n_neighbors=15)\n    sc.tl.umap(adata_viz, min_dist=0.3)\n    results[model_name]['adata_viz'] = adata_viz\n\nprint_success(\"Computed UMAP for all models\")\nprint()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ==================================================\n# Publication-Quality Figure"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ==================================================\n\nprint_section(\"Generating publication-quality figure\")\n\n# Global style\nplt.rcParams.update({\n    'font.family': 'sans-serif',\n    'font.sans-serif': ['Ubuntu', 'DejaVu Sans', 'Liberation Sans', 'sans-serif'],\n    'font.size': 10,\n    'axes.labelsize': 11,\n    'axes.titlesize': 12,\n    'xtick.labelsize': 10,\n    'ytick.labelsize': 10,\n    'legend.fontsize': 8,\n    'figure.dpi': 150,\n    'savefig.dpi': 300,\n    'pdf.fonttype': 42,\n    'ps.fonttype': 42,\n})\n\n# Colorblind-friendly palette\nMODEL_COLORS = {\n    'iAODE': '#0173B2',\n    'scvi': '#DE8F05',\n    'scanvi': '#029E73',\n    'peakvi': '#CC78BC',\n    'poissonvi': '#CA9161',\n}\n\n# Determine which models are available\nmodel_names_ordered = ['iAODE', 'scvi', 'scanvi', 'peakvi', 'poissonvi']\nmodel_names_plot = [m for m in model_names_ordered if m in results]\n\n# 2\u00d74 layout (top row: metrics; bottom row: UMAPs)\nfig = plt.figure(figsize=(16, 10))\ngs = gridspec.GridSpec(\n    2, 4, figure=fig,\n    left=0.06, right=0.98,\n    top=0.95, bottom=0.12,\n    hspace=0.35, wspace=0.35\n)\n\ndef plot_metric_bar(ax, df_data, metric_col, title, ylabel='Score', ylim=None):\n    \"\"\"Consistent bar plots for numeric metrics.\"\"\"\n    data_plot = df_data[df_data[metric_col].notna()].copy()\n\n    if data_plot.empty:\n        ax.text(0.5, 0.5, 'No data',\n                ha='center', va='center',\n                transform=ax.transAxes, fontsize=11)\n        ax.set_title(title, fontsize=12, fontweight='bold', loc='left')\n        ax.axis('off')\n        return\n\n    x_pos = np.arange(len(data_plot))\n    colors = [\n        MODEL_COLORS.get(m, MODEL_COLORS.get(m.lower(), '#888888'))\n        for m in data_plot['Model']\n    ]\n\n    bars = ax.bar(\n        x_pos, data_plot[metric_col],\n        color=colors, edgecolor='black',\n        linewidth=1.0, alpha=0.85\n    )\n\n    ax.set_xticks(x_pos)\n    ax.set_xticklabels(\n        data_plot['Model'],\n        rotation=0, ha='center', fontweight='bold'\n    )\n    ax.set_ylabel(ylabel, fontsize=11, fontweight='bold')\n    if ylim is not None:\n        ax.set_ylim(ylim)\n    ax.set_title(title, fontsize=12, fontweight='bold', loc='left', pad=10)\n\n    ax.grid(axis='y', alpha=0.3, linestyle='--', linewidth=0.6)\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n    ax.spines['left'].set_linewidth(1.2)\n    ax.spines['bottom'].set_linewidth(1.2)\n\n    for bar in bars:\n        height = bar.get_height()\n        if not np.isnan(height):\n            ax.text(\n                bar.get_x() + bar.get_width() / 2., height,\n                f'{height:.3f}',\n                ha='center',\n                va='bottom' if height >= 0 else 'top',\n                fontsize=9, fontweight='bold'\n            )\n\n# Prepare numeric DataFrame\ndf_plot = df.copy()\nnumeric_cols = ['Manifold Dim', 'Spectral Decay', 'Trajectory Dir', 'Train Time (s)']\nfor col in numeric_cols:\n    df_plot[col] = pd.to_numeric(df_plot[col], errors='coerce')\n\n# Row 1: LSE metrics + training time\nplot_metric_bar(\n    fig.add_subplot(gs[0, 0]),\n    df_plot, 'Manifold Dim',\n    'A. Manifold dimensionality',\n    ylabel='Score', ylim=(0, 1)\n)\nplot_metric_bar(\n    fig.add_subplot(gs[0, 1]),\n    df_plot, 'Spectral Decay',\n    'B. Spectral decay rate',\n    ylabel='Score', ylim=(0, 1)\n)\nplot_metric_bar(\n    fig.add_subplot(gs[0, 2]),\n    df_plot, 'Trajectory Dir',\n    'C. Trajectory directionality',\n    ylabel='Score', ylim=(0, 1)\n)\n\n# Panel D: training time\nax_time = fig.add_subplot(gs[0, 3])\ndf_time = df_plot[df_plot['Train Time (s)'].notna()].copy()\n\nif not df_time.empty:\n    x_pos = np.arange(len(df_time))\n    colors = [\n        MODEL_COLORS.get(m, MODEL_COLORS.get(m.lower(), '#888888'))\n        for m in df_time['Model']\n    ]\n\n    bars = ax_time.bar(\n        x_pos, df_time['Train Time (s)'],\n        color=colors, edgecolor='black',\n        linewidth=1.0, alpha=0.85\n    )\n\n    ax_time.set_xticks(x_pos)\n    ax_time.set_xticklabels(\n        df_time['Model'],\n        rotation=0, ha='center', fontweight='bold'\n    )\n    ax_time.set_ylabel('Time (seconds)', fontsize=11, fontweight='bold')\n    ax_time.set_title('D. Training time', fontsize=12, fontweight='bold', loc='left', pad=10)\n\n    ax_time.grid(axis='y', alpha=0.3, linestyle='--', linewidth=0.6)\n    ax_time.spines['top'].set_visible(False)\n    ax_time.spines['right'].set_visible(False)\n    ax_time.spines['left'].set_linewidth(1.2)\n    ax_time.spines['bottom'].set_linewidth(1.2)\n\n    for bar in bars:\n        height = bar.get_height()\n        ax_time.text(\n            bar.get_x() + bar.get_width() / 2., height,\n            f'{height:.1f}',\n            ha='center', va='bottom',\n            fontsize=9, fontweight='bold'\n        )\nelse:\n    ax_time.text(\n        0.5, 0.5, 'No timing data',\n        ha='center', va='center',\n        transform=ax_time.transAxes, fontsize=11\n    )\n    ax_time.axis('off')\n\n# Row 2: UMAPs colored by paul15 clusters (shared legend)\numap_panels = ['E', 'F', 'G', 'H']\nlegend_artists = []\nlegend_labels = []\n\nfor idx, (model_name, panel_label) in enumerate(zip(model_names_plot[:4], umap_panels)):\n    ax = fig.add_subplot(gs[1, idx])\n\n    if model_name not in results or 'adata_viz' not in results[model_name]:\n        ax.text(\n            0.5, 0.5,\n            f'{model_name.upper()}\\nno UMAP',\n            ha='center', va='center',\n            fontsize=11, color='#666666', style='italic'\n        )\n        ax.set_title(\n            f'{panel_label}. {model_name.upper()}',\n            fontsize=12, fontweight='bold', loc='left', pad=10\n        )\n        ax.axis('off')\n        continue\n\n    adata_viz = results[model_name]['adata_viz']\n    umap_coords = adata_viz.obsm['X_umap']\n\n    if 'paul15_clusters' in adata_viz.obs.columns:\n        # Ensure categorical\n        if not pd.api.types.is_categorical_dtype(adata_viz.obs['paul15_clusters']):\n            adata_viz.obs['paul15_clusters'] = adata_viz.obs['paul15_clusters'].astype('category')\n\n        categories = adata_viz.obs['paul15_clusters'].cat.categories\n        n_cats = len(categories)\n\n        if n_cats <= 10:\n            colors_palette = plt.colormaps['tab10'](np.linspace(0,1,10))[:n_cats]\n        elif n_cats <= 20:\n            colors_palette = plt.colormaps['tab20'](np.linspace(0,1,20))[:n_cats]\n        else:\n            colors_palette = plt.colormaps['gist_ncar'](np.linspace(0,1,n_cats))\n\n        for i, cat in enumerate(categories):\n            mask = adata_viz.obs['paul15_clusters'] == cat\n            scatter = ax.scatter(\n                umap_coords[mask, 0], umap_coords[mask, 1],\n                c=[colors_palette[i]],\n                s=8, alpha=0.7,\n                edgecolors='none', rasterized=True\n            )\n\n            # Collect legend handles from first UMAP only\n            if idx == 0:\n                legend_artists.append(scatter)\n                label = str(cat)\n                if len(label) > 12:\n                    label = label[:11] + '\u2026'\n                legend_labels.append(label)\n    else:\n        # No clusters: plot all cells in one color\n        ax.scatter(\n            umap_coords[:, 0], umap_coords[:, 1],\n            c='#4C72B0',\n            s=8, alpha=0.7,\n            edgecolors='none', rasterized=True\n        )\n\n    ax.set_xlabel('UMAP 1', fontsize=11, fontweight='bold')\n    ax.set_ylabel('UMAP 2', fontsize=11, fontweight='bold')\n    ax.set_title(\n        f'{panel_label}. {model_name.upper()}',\n        fontsize=12, fontweight='bold', loc='left', pad=10\n    )\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n    ax.spines['left'].set_linewidth(1.2)\n    ax.spines['bottom'].set_linewidth(1.2)\n    ax.tick_params(labelsize=10)\n\n# Shared legend beneath the figure\nif legend_artists:\n    n_items = len(legend_labels)\n    n_cols = min(n_items, 8)\n\n    fig.legend(\n        legend_artists, legend_labels,\n        loc='lower center',\n        bbox_to_anchor=(0.5, 0.01),\n        ncol=n_cols,\n        frameon=True,\n        fontsize=8,\n        markerscale=2.5,\n        columnspacing=1.2,\n        handletextpad=0.4,\n        edgecolor='black',\n        framealpha=0.95\n    )\n\n# Save figure\nfig_path_png = OUTPUT_DIR / 'model_comparison.png'\nfig_path_pdf = OUTPUT_DIR / 'model_comparison.pdf'\nplt.savefig(fig_path_png, dpi=300, bbox_inches='tight')\nplt.savefig(fig_path_pdf, dpi=300, bbox_inches='tight')\nplt.close()\n\nprint_success(f\"Saved figure: {fig_path_png}\")\nprint_success(f\"Saved figure: {fig_path_pdf}\")\nprint()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ==================================================\n# Summary"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ==================================================\n\nprint_header(\"Evaluation complete\")\nprint_info(\"Model benchmarking summary \u2013 latent space evaluation\")\nprint()\nprint(f\"  Configuration: {CONFIG['epochs']} epochs, latent_dim={CONFIG['latent_dim']}\")\nprint(f\"  Dataset: {adata.n_obs:,} cells (test: {len(splitter.test_idx):,})\")\nprint()\nprint(\"  Performance (test latent space):\")\nfor model_name in model_names_plot:\n    data = results[model_name]\n    metrics_str = []\n    if 'ls_metrics' in data:\n        m = data['ls_metrics']\n        if 'manifold_dimensionality' in m:\n            metrics_str.append(f\"ManifoldDim={m['manifold_dimensionality']:.3f}\")\n        if 'spectral_decay_rate' in m:\n            metrics_str.append(f\"SpectralDecay={m['spectral_decay_rate']:.3f}\")\n        if 'trajectory_directionality' in m:\n            metrics_str.append(f\"TrajDir={m['trajectory_directionality']:.3f}\")\n    print(f\"    {model_name.upper():12s}: {data['train_time']:6.1f}s, {', '.join(metrics_str)}\")\nprint()\n\nprint_info(\"Output files:\")\nprint(f\"  \u2022 {OUTPUT_DIR}/model_comparison.csv\")\nprint(f\"  \u2022 {OUTPUT_DIR}/model_comparison.png\")\nprint(f\"  \u2022 {OUTPUT_DIR}/model_comparison.pdf\")\nprint()\nprint_info(\"All scores computed using LSE (Latent Space Evaluation) on the test latent spaces.\")\nprint()"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}