{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Evaluation (scATAC-seq)\n\nConverted from `examples/model_evaluation_atac.py`\n\n**Note:** This notebook contains the full example code. Run cells sequentially."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "\"\"\"\nModel evaluation and benchmarking (scATAC-seq)\n\nCompare iAODE with scVI-family models using latent space evaluation metrics.\n\nDataset: 10X Mouse Brain 5k scATAC-seq (HVP subset)\n\"\"\"\n\nimport sys\nfrom pathlib import Path\n\nsys.path.insert(0, str(Path(__file__).parent))\nfrom _example_utils import (\n    check_iaode_installed, setup_output_dir,\n    print_header, print_section, print_success, print_info, print_warning\n)\n\nif not check_iaode_installed():\n    sys.exit(1)\n\nimport iaode\nimport scanpy as sc  # type: ignore\nimport numpy as np\nimport pandas as pd  # type: ignore\nimport matplotlib.pyplot as plt\nfrom matplotlib import gridspec\nfrom mpl_toolkits.axes_grid1 import make_axes_locatable  # type: ignore\nimport warnings\nwarnings.filterwarnings('ignore')"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ==================================================\n# Configuration"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ==================================================\n\nCONFIG = {\n    'epochs': 100,\n    'patience': 20,\n    'val_every': 5,\n    'latent_dim': 10,\n    'hidden_dim': 128,\n    'batch_size': 128,\n    'test_size': 0.15,\n    'val_size': 0.15,\n    'random_seed': 42,\n    'n_hvp': 20000,  # Number of highly variable peaks\n}\n\nOUTPUT_DIR = setup_output_dir(\"model_evaluation_atac\")\nprint_info(f\"Saving outputs to: {OUTPUT_DIR}\")\nprint_info(f\"Config: {CONFIG['epochs']} epochs, latent_dim={CONFIG['latent_dim']}, HVP={CONFIG['n_hvp']}\")\nprint()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ==================================================\n# Load and Annotate scATAC Data"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ==================================================\n\nprint_header(\"Model evaluation & benchmarking (scATAC-seq)\")\n\nprint_section(\"Loading and annotating scATAC-seq data\")\nprint_info(\"Dataset: 10X Mouse Brain 5k scATAC-seq\")\n\n# Download and annotate data\nh5_file, gtf_file = iaode.datasets.mouse_brain_5k_atacseq()\n\nadata = iaode.annotation_pipeline(\n    h5_file=str(h5_file),\n    gtf_file=str(gtf_file),\n    promoter_upstream=2000,\n    promoter_downstream=500,\n    apply_tfidf=True,\n    select_hvp=True,\n    n_top_peaks=int(CONFIG['n_hvp'])\n)\n\nprint_success(f\"Annotated: {adata.n_obs:,} cells \u00d7 {adata.n_vars:,} peaks\")"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ==================================================\n# Subset to HVPs Only"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ==================================================\n\nprint_section(\"Subsetting to highly variable peaks (HVPs)\")\n\nif 'highly_variable' in adata.var.columns:\n    n_total_peaks = adata.n_vars\n    n_hvp = adata.var['highly_variable'].sum()\n    \n    # Subset to HVPs\n    adata = adata[:, adata.var['highly_variable']].copy()\n    \n    print_success(f\"HVP subset: {adata.n_obs:,} cells \u00d7 {adata.n_vars:,} peaks\")\n    print_info(f\"  Retained {n_hvp:,} / {n_total_peaks:,} peaks ({n_hvp/n_total_peaks*100:.1f}%)\")\nelse:\n    print_warning(\"No HVP flag found; using all peaks\")\n\nprint()\n\n# Ensure counts layer exists\nif 'counts' not in adata.layers:\n    from scipy.sparse import issparse  # type: ignore\n    if issparse(adata.X):\n        adata.layers['counts'] = adata.X.copy()\n    else:\n        adata.layers['counts'] = np.asarray(adata.X.copy())\n\n# Peak statistics for visualization\ntry:\n    peak_counts_mat = adata.X.sum(axis=1)  # type: ignore[call-arg]\n    if hasattr(peak_counts_mat, 'A1'):\n        peak_counts = peak_counts_mat.A1\n    else:\n        peak_counts = np.asarray(peak_counts_mat).ravel()\nexcept Exception:\n    peak_counts = np.asarray(adata.X).sum(axis=1)\n\nadata.obs['n_peaks'] = peak_counts"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ==================================================\n# Create Train/Val/Test Split"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ==================================================\n\nprint_section(\"Creating train/validation/test splits\")\n\nsplitter = iaode.DataSplitter(\n    n_samples=adata.n_obs,\n    test_size=CONFIG['test_size'],\n    val_size=CONFIG['val_size'],\n    random_state=CONFIG['random_seed']\n)\n\nprint_info(f\"Train: {len(splitter.train_idx)} | Val: {len(splitter.val_idx)} | Test: {len(splitter.test_idx)} cells\")\nprint()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ==================================================\n# Train iAODE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ==================================================\n\nprint_section(\"Training iAODE\")\n\nmodel = iaode.agent(\n    adata, \n    layer='counts',\n    latent_dim=int(CONFIG['latent_dim']),\n    hidden_dim=int(CONFIG['hidden_dim']),\n    use_ode=True,\n    encoder_type='mlp',\n    loss_mode='mse',  # MSE for TF-IDF-normalized scATAC data\n    batch_size=int(CONFIG['batch_size'])\n)\n\nmodel.fit(\n    epochs=int(CONFIG['epochs']),\n    patience=int(CONFIG['patience']),\n    val_every=int(CONFIG['val_every'])\n)\n\nlatent_iaode = model.get_latent()\nmetrics_iaode = model.get_resource_metrics()\n\nprint_success(f\"iAODE trained in {metrics_iaode['train_time']:.2f}s ({metrics_iaode['actual_epochs']} epochs)\")\nprint_info(f\"  Peak GPU memory: {metrics_iaode['peak_memory_gb']:.3f} GB\")\nprint()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ==================================================\n# Evaluate iAODE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ==================================================\n\nprint_section(\"Evaluating iAODE on test set\")\n\nlatent_iaode_test = latent_iaode[splitter.test_idx]\nX_high_test = adata[splitter.test_idx].layers['counts']\nif hasattr(X_high_test, 'toarray'):\n    X_high_test = X_high_test.toarray()\n\n# Latent space evaluation metrics\nprint_info(\"Computing latent space evaluation (LSE) metrics...\")\nls_metrics = iaode.evaluate_single_cell_latent_space(\n    latent_space=latent_iaode_test,\n    data_type='trajectory',\n    verbose=True\n)\n\nresults = {\n    'iAODE': {\n        'latent': latent_iaode_test,\n        'adata_subset': adata[splitter.test_idx].copy(),\n        'train_time': metrics_iaode['train_time'],\n        'epochs': metrics_iaode['actual_epochs'],\n        'ls_metrics': ls_metrics\n    }\n}\n\nprint()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ==================================================\n# Train and Evaluate scVI Models"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ==================================================\n\nprint_section(\"Training scVI-family models\")\n\nscvi_results = iaode.train_scvi_models(\n    adata, splitter,\n    n_latent=CONFIG['latent_dim'],\n    n_epochs=CONFIG['epochs'],\n    batch_size=CONFIG['batch_size']\n)\n\nprint_section(\"Evaluating scVI-family models\")\n\nfor model_name, result in scvi_results.items():\n    if result is not None:\n        print_info(f\"Evaluating {model_name.upper()}\")\n        \n        latent_scvi = result['model'].get_latent_representation(result['adata_test'])\n        \n        # Latent space evaluation metrics\n        try:\n            ls_scvi = iaode.evaluate_single_cell_latent_space(\n                latent_space=latent_scvi,\n                data_type='trajectory',\n                verbose=False\n            )\n        except Exception as e:\n            print_warning(f\"LSE metrics failed for {model_name}: {e}\")\n            ls_scvi = {}\n        \n        results[model_name] = {\n            'latent': latent_scvi,\n            'adata_subset': result['adata_test'].copy(),\n            'train_time': result['train_time'],\n            'epochs': result.get('epochs', CONFIG['epochs']),\n            'ls_metrics': ls_scvi\n        }\n        \n        print_success(f\"{model_name.upper()} evaluated\")\n\nprint()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ==================================================\n# Create Comparison Table"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ==================================================\n\nprint_section(\"Building comparison table\")\n\ncomparison_data = []\nfor model_name, data in results.items():\n    row = {\n        'Model': model_name,\n        'Train Time (s)': data['train_time'],\n        'Epochs': data['epochs']\n    }\n    \n    # Latent space evaluation metrics\n    ls = data.get('ls_metrics', {})\n    row['Manifold Dim'] = ls.get('manifold_dimensionality', np.nan)\n    row['Spectral Decay'] = ls.get('spectral_decay_rate', np.nan)\n    row['Trajectory Dir'] = ls.get('trajectory_directionality', np.nan)\n    \n    comparison_data.append(row)\n\ndf = pd.DataFrame(comparison_data)\nprint()\nprint(df.to_string(index=False))\nprint()\n\ncsv_path = OUTPUT_DIR / 'model_comparison.csv'\ndf.to_csv(csv_path, index=False)\nprint_success(f\"Saved table: {csv_path}\")\nprint()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ==================================================\n# Compute UMAP for Visualization"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ==================================================\n\nprint_section(\"Computing UMAP embeddings\")\n\nfor model_name, data in results.items():\n    adata_viz = data['adata_subset'].copy()\n    adata_viz.obsm['X_latent'] = data['latent']\n    sc.pp.neighbors(adata_viz, use_rep='X_latent', n_neighbors=15)\n    sc.tl.umap(adata_viz, min_dist=0.3)\n    results[model_name]['adata_viz'] = adata_viz\n    print_info(f\"  Computed UMAP for {model_name.upper()}\")\n\nprint()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ==================================================\n# Generate Multi-Panel Figure"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ==================================================\n\nprint_section(\"Generating multi-panel figure\")\n\n# Global style with Ubuntu-like sans serif font\nplt.rcParams.update({\n    'font.family': 'sans-serif',\n    'font.sans-serif': ['Ubuntu', 'DejaVu Sans', 'Liberation Sans', 'sans-serif'],\n    'font.size': 10,\n    'axes.labelsize': 11,\n    'axes.titlesize': 12,\n    'xtick.labelsize': 10,\n    'ytick.labelsize': 10,\n    'legend.fontsize': 9,\n    'figure.dpi': 150,\n    'savefig.dpi': 300,\n    'pdf.fonttype': 42,\n    'ps.fonttype': 42,\n})\n\n# Colorblind-friendly palette\nMODEL_COLORS = {\n    'iAODE': '#0173B2',\n    'scvi': '#DE8F05',\n    'scanvi': '#029E73',\n    'peakvi': '#CC79A7',\n    'poissonvi': '#CA9161'\n}\n\n# Include all trained models (up to 5)\nmodel_names_ordered = ['iAODE', 'peakvi', 'poissonvi', 'scvi', 'scanvi']\nmodel_names_plot = [m for m in model_names_ordered if m in results.keys()][:5]\n\nn_models = len(model_names_plot)\nprint_info(f\"Visualizing models: {', '.join([m.upper() for m in model_names_plot])}\")\n\n# 3-row layout, up to 5 columns\nfig = plt.figure(figsize=(3.2 * n_models, 12))\ngs = gridspec.GridSpec(3, n_models, figure=fig,\n                       left=0.07, right=0.98,\n                       top=0.96, bottom=0.06,\n                       hspace=0.30, wspace=0.30)\n\ndef style_axis(ax, grid=True):\n    \"\"\"Consistent axis styling.\"\"\"\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n    ax.spines['left'].set_linewidth(1.2)\n    ax.spines['bottom'].set_linewidth(1.2)\n    ax.tick_params(width=1.2, labelsize=10)\n    if grid:\n        ax.grid(axis='y', alpha=0.3, linestyle='--', linewidth=0.6)\n\ndef plot_metric_bar(ax, df_data, metric_col, title, ylabel='Score', ylim=None):\n    \"\"\"Bar plot helper for metric comparison.\"\"\"\n    data_plot = df_data[df_data[metric_col].notna()].copy()\n    \n    if data_plot.empty:\n        ax.text(\n            0.5, 0.5, 'No data',\n            ha='center', va='center',\n            transform=ax.transAxes,\n            fontsize=12, color='#666666', style='italic'\n        )\n        ax.set_title(title, fontsize=12, fontweight='bold', loc='left')\n        ax.axis('off')\n        return\n    \n    x_pos = np.arange(len(data_plot))\n    colors = [MODEL_COLORS.get(m, MODEL_COLORS.get(m.lower(), '#888888'))\n              for m in data_plot['Model']]\n    \n    bars = ax.bar(\n        x_pos, data_plot[metric_col],\n        color=colors, edgecolor='black',\n        linewidth=1.2, alpha=0.85, width=0.7\n    )\n    \n    ax.set_xticks(x_pos)\n    ax.set_xticklabels(\n        data_plot['Model'],\n        rotation=0, ha='center',\n        fontweight='bold', fontsize=10\n    )\n    ax.set_ylabel(ylabel, fontsize=11, fontweight='bold')\n    if ylim:\n        ax.set_ylim(ylim)\n    ax.set_title(title, fontsize=12, fontweight='bold', loc='left', pad=10)\n    style_axis(ax, grid=True)\n    \n    # Numeric labels on bars\n    for bar in bars:\n        height = bar.get_height()\n        if not np.isnan(height):\n            ax.text(\n                bar.get_x() + bar.get_width() / 2., height,\n                f'{height:.3f}',\n                ha='center',\n                va='bottom' if height >= 0 else 'top',\n                fontsize=9, fontweight='bold'\n            )\n\n# Prepare numeric dataframe\ndf_plot = df.copy()\nnumeric_cols = ['Manifold Dim', 'Spectral Decay', 'Trajectory Dir', 'Train Time (s)']\nfor col in numeric_cols:\n    df_plot[col] = pd.to_numeric(df_plot[col], errors='coerce')\n\n# Row 1: Latent space metrics + training time\nmetric_cols = ['Manifold Dim', 'Spectral Decay', 'Trajectory Dir', 'Train Time (s)']\nmetric_titles = [\n    'A. Manifold dimensionality',\n    'B. Spectral decay rate',\n    'C. Trajectory directionality',\n    'D. Training time'\n]\nmetric_ylabels = ['Score', 'Score', 'Score', 'Time (seconds)']\nmetric_ylims = [(0, 1), (0, 1), (0, 1), None]\n\nfor idx in range(n_models):\n    ax = fig.add_subplot(gs[0, idx])\n    \n    if idx < len(metric_cols):\n        col = metric_cols[idx]\n        title = metric_titles[idx]\n        ylabel = metric_ylabels[idx]\n        ylim = metric_ylims[idx]\n        \n        if col == 'Train Time (s)':\n            # Special handling for training time\n            df_time = df_plot[df_plot[col].notna()].copy()\n            if not df_time.empty:\n                x_pos = np.arange(len(df_time))\n                colors = [MODEL_COLORS.get(m, MODEL_COLORS.get(m.lower(), '#888888'))\n                          for m in df_time['Model']]\n                \n                bars = ax.bar(\n                    x_pos, df_time[col],\n                    color=colors, edgecolor='black',\n                    linewidth=1.2, alpha=0.85, width=0.7\n                )\n                \n                ax.set_xticks(x_pos)\n                ax.set_xticklabels(\n                    df_time['Model'],\n                    rotation=0, ha='center',\n                    fontweight='bold', fontsize=10\n                )\n                ax.set_ylabel(ylabel, fontsize=11, fontweight='bold')\n                ax.set_title(title, fontsize=12, fontweight='bold', loc='left', pad=10)\n                style_axis(ax, grid=True)\n                \n                for bar in bars:\n                    height = bar.get_height()\n                    ax.text(\n                        bar.get_x() + bar.get_width() / 2., height,\n                        f'{height:.1f}',\n                        ha='center', va='bottom',\n                        fontsize=9, fontweight='bold'\n                    )\n        else:\n            plot_metric_bar(ax, df_plot, col, title, ylabel=ylabel, ylim=ylim)\n    else:\n        ax.axis('off')\n\ndef style_umap_ax(ax, xlim=None, ylim=None):\n    \"\"\"Consistent styling for UMAP axes.\"\"\"\n    ax.set_xlabel('UMAP 1', fontsize=11, fontweight='bold')\n    ax.set_ylabel('UMAP 2', fontsize=11, fontweight='bold')\n    if lim_x is not None:\n        ax.set_xlim(lim_x)\n    if lim_y is not None:\n        ax.set_ylim(lim_y)\n    ax.set_aspect('equal', adjustable='box')\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n    ax.spines['left'].set_linewidth(1.2)\n    ax.spines['bottom'].set_linewidth(1.2)\n    ax.tick_params(width=1.2, labelsize=10)\n\ndef add_colorbar(fig, ax, scatter, label):\n    \"\"\"Attach a colorbar with consistent style.\"\"\"\n    divider = make_axes_locatable(ax)\n    cax = divider.append_axes(\"right\", size=\"4%\", pad=0.08)\n    cbar = plt.colorbar(scatter, cax=cax)\n    cbar.set_label(label, fontsize=10, fontweight='bold')\n    cbar.ax.tick_params(labelsize=9, width=1.0)\n    cbar.outline.set_linewidth(1.2)\n    return cbar\n\n# Shared color ranges\nall_peak_counts = []\nall_latent_dim1 = []\nfor model_name in model_names_plot:\n    if model_name in results and 'adata_viz' in results[model_name]:\n        all_peak_counts.extend(results[model_name]['adata_viz'].obs['n_peaks'].values)\n        all_latent_dim1.extend(results[model_name]['latent'][:, 0])\n\nvmin_peaks = np.percentile(all_peak_counts, 2)\nvmax_peaks = np.percentile(all_peak_counts, 98)\nvmin_latent = np.percentile(all_latent_dim1, 2)\nvmax_latent = np.percentile(all_latent_dim1, 98)\n\n# Shared UMAP axis limits\nall_x = []\nall_y = []\nfor model_name in model_names_plot:\n    if model_name in results and 'adata_viz' in results[model_name]:\n        umap_coords = results[model_name]['adata_viz'].obsm['X_umap']\n        all_x.extend(umap_coords[:, 0])\n        all_y.extend(umap_coords[:, 1])\n\nx_min, x_max = np.min(all_x), np.max(all_x)\ny_min, y_max = np.min(all_y), np.max(all_y)\npadding = 0.05\nx_range = x_max - x_min\ny_range = y_max - y_min\nlim_x: tuple[float, float] = (x_min - padding * x_range, x_max + padding * x_range)\nlim_y: tuple[float, float] = (y_min - padding * y_range, y_max + padding * y_range)\n\n# Row 2: UMAP colored by peak counts\npanel_labels_row2 = ['E', 'F', 'G', 'H', 'I']\n\nfor idx, model_name in enumerate(model_names_plot):\n    ax = fig.add_subplot(gs[1, idx])\n    panel_label = panel_labels_row2[idx] if idx < len(panel_labels_row2) else f\"P{idx+1}\"\n    \n    if model_name in results and 'adata_viz' in results[model_name]:\n        adata_viz = results[model_name]['adata_viz']\n        umap_coords = adata_viz.obsm['X_umap']\n        color_values = adata_viz.obs['n_peaks'].values\n        \n        scatter = ax.scatter(\n            umap_coords[:, 0], umap_coords[:, 1],\n            c=color_values,\n            cmap='YlOrRd',\n            s=15,\n            alpha=0.8,\n            edgecolors='none',\n            rasterized=True,\n            vmin=vmin_peaks,\n            vmax=vmax_peaks\n        )\n        \n        style_umap_ax(ax, xlim=lim_x, ylim=lim_y)\n        ax.set_title(\n            f'{panel_label}. {model_name.upper()} - peak counts',\n            fontsize=11, fontweight='bold', loc='left', pad=8\n        )\n        \n        # Colorbar only on last panel\n        if idx == len(model_names_plot) - 1:\n            add_colorbar(fig, ax, scatter, 'Peak counts')\n    else:\n        ax.text(\n            0.5, 0.5, f'{model_name.upper()}\\nnot available',\n            ha='center', va='center', fontsize=11,\n            color='#666666', style='italic'\n        )\n        ax.set_title(\n            f'{panel_label}. {model_name.upper()}',\n            fontsize=11, fontweight='bold', loc='left', pad=8\n        )\n        ax.axis('off')\n\n# Row 3: UMAP colored by latent dimension 1\npanel_labels_row3 = ['J', 'K', 'L', 'M', 'N']\n\nfor idx, model_name in enumerate(model_names_plot):\n    ax = fig.add_subplot(gs[2, idx])\n    panel_label = panel_labels_row3[idx] if idx < len(panel_labels_row3) else f\"Q{idx+1}\"\n    \n    if model_name in results and 'adata_viz' in results[model_name]:\n        adata_viz = results[model_name]['adata_viz']\n        umap_coords = adata_viz.obsm['X_umap']\n        latent = results[model_name]['latent']\n        color_values = latent[:, 0]\n        \n        scatter = ax.scatter(\n            umap_coords[:, 0], umap_coords[:, 1],\n            c=color_values,\n            cmap='viridis',\n            s=15,\n            alpha=0.8,\n            edgecolors='none',\n            rasterized=True,\n            vmin=vmin_latent,\n            vmax=vmax_latent\n        )\n        \n        style_umap_ax(ax, xlim=lim_x, ylim=lim_y)\n        ax.set_title(\n            f'{panel_label}. {model_name.upper()} - latent dim 1',\n            fontsize=11, fontweight='bold', loc='left', pad=8\n        )\n        \n        # Colorbar only on last panel\n        if idx == len(model_names_plot) - 1:\n            add_colorbar(fig, ax, scatter, 'Latent dim 1')\n    else:\n        ax.text(\n            0.5, 0.5, f'{model_name.upper()}\\nnot available',\n            ha='center', va='center', fontsize=11,\n            color='#666666', style='italic'\n        )\n        ax.set_title(\n            f'{panel_label}. {model_name.upper()}',\n            fontsize=11, fontweight='bold', loc='left', pad=8\n        )\n        ax.axis('off')\n\n# Save figure\nplt.savefig(OUTPUT_DIR / 'model_comparison.png', dpi=300, bbox_inches='tight')\nplt.savefig(OUTPUT_DIR / 'model_comparison.pdf', dpi=300, bbox_inches='tight')\nplt.close()\n\nprint_success(f\"Saved figure: {OUTPUT_DIR}/model_comparison.png\")\nprint_success(f\"Saved figure: {OUTPUT_DIR}/model_comparison.pdf\")\nprint()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ==================================================\n# Summary"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ==================================================\n\nprint_header(\"Evaluation complete\")\nprint_info(\"scATAC-seq model benchmarking (HVP subset)\")\nprint()\nprint(\"  Configuration:\")\nprint(\"    \u2022 Dataset: 10X Mouse Brain 5k scATAC-seq\")\nprint(f\"    \u2022 HVP subset: {adata.n_vars:,} peaks\")\nprint(f\"    \u2022 Test cells: {len(splitter.test_idx):,}\")\nprint(f\"    \u2022 Epochs: {CONFIG['epochs']}\")\nprint(f\"    \u2022 Latent dim: {CONFIG['latent_dim']}\")\nprint()\nprint(\"  Performance summary:\")\nfor model_name in model_names_plot:\n    if model_name in results:\n        data = results[model_name]\n        metrics_str = []\n        if 'ls_metrics' in data and 'manifold_dimensionality' in data['ls_metrics']:\n            metrics_str.append(f\"ManifoldDim={data['ls_metrics']['manifold_dimensionality']:.3f}\")\n        if 'ls_metrics' in data and 'spectral_decay_rate' in data['ls_metrics']:\n            metrics_str.append(f\"SpectralDecay={data['ls_metrics']['spectral_decay_rate']:.3f}\")\n        if 'ls_metrics' in data and 'trajectory_directionality' in data['ls_metrics']:\n            metrics_str.append(f\"TrajDir={data['ls_metrics']['trajectory_directionality']:.3f}\")\n        print(f\"    {model_name.upper():12s}: {data['train_time']:6.1f}s, {', '.join(metrics_str)}\")\nprint()\n\nprint_info(\"Output files:\")\nprint(f\"  \u2022 {OUTPUT_DIR}/model_comparison.csv\")\nprint(f\"  \u2022 {OUTPUT_DIR}/model_comparison.png\")\nprint(f\"  \u2022 {OUTPUT_DIR}/model_comparison.pdf\")\nprint()\n\nprint_info(\"Visualization layout:\")\nprint(\"  \u2022 Row 1: Latent space metrics + training time\")\nprint(\"  \u2022 Row 2: UMAP colored by peak counts (shared scale)\")\nprint(\"  \u2022 Row 3: UMAP colored by latent dim 1 (shared scale)\")\nprint(\"  \u2022 All UMAPs share axis limits and color ranges for fair comparison\")\nprint()"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}